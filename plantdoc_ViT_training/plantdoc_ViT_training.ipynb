{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4be2c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "\n",
    "# def is_corrupted_image(image_path):\n",
    "#     try:\n",
    "#         # Attempt to open the image\n",
    "#         with Image.open(image_path) as img:\n",
    "#             # Try to access basic properties to check if the image is valid\n",
    "#             img.verify()\n",
    "#             return False\n",
    "#     except (IOError, SyntaxError):\n",
    "#         # Image is corrupted or not supported\n",
    "#         return True\n",
    "\n",
    "# def check_and_remove_corrupted_images(directory):\n",
    "#     k=0\n",
    "#     total=0\n",
    "#     for root, dirs, files in os.walk(directory):\n",
    "#         for file in files:\n",
    "#             file_path = os.path.join(root, file)\n",
    "\n",
    "#             # Check if the file is an image (you can customize this check based on file extensions)\n",
    "#             if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "#                 if is_corrupted_image(file_path):\n",
    "#                     # Remove the corrupted image\n",
    "#                     os.remove(file_path)\n",
    "#                     print(f\"Removed corrupted image: {file_path}\")\n",
    "#                     k+=1\n",
    "#                 else:\n",
    "#                     # Print the shape of the valid image\n",
    "#                     with Image.open(file_path) as img:\n",
    "# #                         print(f\"Image shape of {file_path}: {img.size}\")\n",
    "#                         print(img.layers)\n",
    "#                     total+=1\n",
    "#     print(k)\n",
    "#     print(total)\n",
    "\n",
    "# # Replace 'your_directory_path' with the actual path to your directory containing the 29 directories\n",
    "# directory_path = './cropped_images_dataset'\n",
    "# check_and_remove_corrupted_images(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5476aaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/suryansh/.local/lib/python3.10/site-packages (4.36.1)\n",
      "Requirement already satisfied: datasets>=1.17.0 in /home/suryansh/.local/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorboard in /home/suryansh/.local/lib/python3.10/site-packages (2.15.1)\n",
      "Requirement already satisfied: filelock in /home/suryansh/.local/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/suryansh/.local/lib/python3.10/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/suryansh/.local/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/suryansh/.local/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/suryansh/.local/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/suryansh/.local/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/suryansh/.local/lib/python3.10/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/suryansh/.local/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/suryansh/.local/lib/python3.10/site-packages (from datasets>=1.17.0) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/suryansh/.local/lib/python3.10/site-packages (from datasets>=1.17.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/suryansh/.local/lib/python3.10/site-packages (from datasets>=1.17.0) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/suryansh/.local/lib/python3.10/site-packages (from datasets>=1.17.0) (2.1.3)\n",
      "Requirement already satisfied: xxhash in /home/suryansh/.local/lib/python3.10/site-packages (from datasets>=1.17.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/suryansh/.local/lib/python3.10/site-packages (from datasets>=1.17.0) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/suryansh/.local/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets>=1.17.0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/suryansh/.local/lib/python3.10/site-packages (from datasets>=1.17.0) (3.9.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/suryansh/.local/lib/python3.10/site-packages (from tensorboard) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/suryansh/.local/lib/python3.10/site-packages (from tensorboard) (1.59.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/suryansh/.local/lib/python3.10/site-packages (from tensorboard) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/suryansh/.local/lib/python3.10/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/suryansh/.local/lib/python3.10/site-packages (from tensorboard) (3.5.1)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /home/suryansh/.local/lib/python3.10/site-packages (from tensorboard) (4.23.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard) (59.6.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/suryansh/.local/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/suryansh/.local/lib/python3.10/site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/suryansh/.local/lib/python3.10/site-packages (from aiohttp->datasets>=1.17.0) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/suryansh/.local/lib/python3.10/site-packages (from aiohttp->datasets>=1.17.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/suryansh/.local/lib/python3.10/site-packages (from aiohttp->datasets>=1.17.0) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/suryansh/.local/lib/python3.10/site-packages (from aiohttp->datasets>=1.17.0) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/suryansh/.local/lib/python3.10/site-packages (from aiohttp->datasets>=1.17.0) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/suryansh/.local/lib/python3.10/site-packages (from aiohttp->datasets>=1.17.0) (4.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/suryansh/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/suryansh/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/suryansh/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/suryansh/.local/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/suryansh/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/suryansh/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/suryansh/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/suryansh/.local/lib/python3.10/site-packages (from pandas->datasets>=1.17.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets>=1.17.0) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/suryansh/.local/lib/python3.10/site-packages (from pandas->datasets>=1.17.0) (2023.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/suryansh/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install \"tensorflow==2.6.0\"\n",
    "!pip install transformers \"datasets>=1.17.0\" tensorboard --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f27867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "647ca002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06cd583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/vit-base-patch16-224-in21k\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07624179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datasets\n",
    "\n",
    "def create_image_folder_dataset(root_path):\n",
    "    \"\"\"creates `Dataset` from image folder structure\"\"\"\n",
    "\n",
    "    # get class names by folders names\n",
    "    _CLASS_NAMES= os.listdir(root_path)\n",
    "    # defines `datasets` features`\n",
    "    features=datasets.Features({\n",
    "                      \"img\": datasets.Image(),\n",
    "                      \"label\": datasets.features.ClassLabel(names=_CLASS_NAMES),\n",
    "                  })\n",
    "    # temp list holding datapoints for creation\n",
    "    img_data_files=[]\n",
    "    label_data_files=[]\n",
    "    # load images into list for creation\n",
    "    for img_class in os.listdir(root_path):\n",
    "        for img in os.listdir(os.path.join(root_path,img_class)):\n",
    "            path_=os.path.join(root_path,img_class,img)\n",
    "            img_data_files.append(path_)\n",
    "            label_data_files.append(img_class)\n",
    "    # create dataset\n",
    "    ds = datasets.Dataset.from_dict({\"img\":img_data_files,\"label\":label_data_files},features=features)\n",
    "    return ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "524e8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "eurosat_ds = create_image_folder_dataset(\"./cropped_images_dataset/train\")\n",
    "eurosat_ds_test=create_image_folder_dataset(\"./cropped_images_dataset/validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52685247",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_class_labels = eurosat_ds.features[\"label\"].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5859cd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 18:09:27.692779: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-17 18:09:27.713272: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-17 18:09:27.713291: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-17 18:09:27.714025: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-17 18:09:27.718244: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-17 18:09:28.164952: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/suryansh/anaconda3/lib/python3.11/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "2023-12-17 18:09:29.246452: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-17 18:09:29.248038: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-17 18:09:29.248106: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-17 18:09:29.254282: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-17 18:09:29.254405: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-17 18:09:29.254505: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-17 18:09:29.345536: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-17 18:09:29.345625: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-17 18:09:29.345680: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-17 18:09:29.345730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6263 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTFeatureExtractor\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_id)\n",
    "\n",
    "# learn more about data augmentation here: https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Resizing(feature_extractor.size['height'], feature_extractor.size['width']),\n",
    "        layers.Rescaling(1./255),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# use keras image data augementation processing\n",
    "def augmentation(examples):\n",
    "    # print(examples[\"img\"])\n",
    "    data=[]\n",
    "    for image in examples['img']:\n",
    "        data.append(data_augmentation(image))\n",
    "    examples[\"pixel_values\"] = data\n",
    "    return examples\n",
    "\n",
    "\n",
    "# basic processing (only resizing)\n",
    "def process(examples):\n",
    "    examples.update(feature_extractor(examples['img'], ))\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3729d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are also renaming our label col to labels to use `.to_tf_dataset` later\n",
    "eurosat_ds = eurosat_ds.rename_column(\"label\", \"labels\")\n",
    "eurosat_ds_test=eurosat_ds_test.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20c7612d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['img', 'labels', 'pixel_values'],\n",
       "    num_rows: 7401\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processed_dataset = eurosat_ds.map(process, batched=True)\n",
    "\n",
    "# # augmenting dataset takes a lot of time\n",
    "processed_dataset = eurosat_ds.map(process, batched=True)\n",
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d36b8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7401"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42bbeb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/606 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['img', 'labels', 'pixel_values'],\n",
       "    num_rows: 606\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset_test=eurosat_ds_test.map(process, batched=True)\n",
    "processed_dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "497be668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 Laptop GPU, compute capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 18:10:09.314839: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "import tensorflow as tf\n",
    "\n",
    "id2label = {str(i): label for i, label in enumerate(img_class_labels)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "num_train_epochs = 20\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 32\n",
    "learning_rate = 3e-5\n",
    "weight_decay_rate=0.01\n",
    "num_warmup_steps=0\n",
    "output_dir=model_id.split(\"/\")[1]\n",
    "# hub_token = HfFolder.get_token() # or your token directly \"hf_xxx\"\n",
    "# hub_model_id = f'{model_id.split(\"/\")[1]}-euroSat'\n",
    "fp16=True\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "# Comment this line out if you're using a GPU that will not benefit from this\n",
    "if fp16:\n",
    "    tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1835ea54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suryansh/anaconda3/lib/python3.11/site-packages/datasets/arrow_dataset.py:388: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "# Data collator that will dynamically pad the inputs received, as well as the labels.\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "# Function to process a single example\n",
    "def process_example(example):\n",
    "    # Transpose the pixel_values tensor to have channels dimension at the beginning\n",
    "    example['pixel_values'] = tf.transpose(example['pixel_values'], perm=[0, 3, 2, 1])\n",
    "    return example\n",
    "\n",
    "# Modify the processed_dataset directly\n",
    "# processed_dataset = processed_dataset.map(\n",
    "#     process_example,\n",
    "#     batched=True,\n",
    "#     num_proc=1  # Set the number of processes according to your system capabilities\n",
    "# )\n",
    "# processed_dataset_test = processed_dataset_test.map(\n",
    "#     process_example,\n",
    "#     batched=True,\n",
    "#     num_proc=1  # Set the number of processes according to your system capabilities\n",
    "# )\n",
    "# converting our train dataset to tf.data.Dataset\n",
    "tf_train_dataset = processed_dataset.to_tf_dataset(\n",
    "   columns=['pixel_values'],\n",
    "   label_cols=[\"labels\"],\n",
    "   shuffle=True,\n",
    "   batch_size=train_batch_size,\n",
    "   collate_fn=data_collator)\n",
    "\n",
    "# converting our test dataset to tf.data.Dataset\n",
    "tf_eval_dataset = processed_dataset_test.to_tf_dataset(\n",
    "   columns=['pixel_values'],\n",
    "   label_cols=[\"labels\"],\n",
    "   shuffle=True,\n",
    "   batch_size=eval_batch_size,\n",
    "   collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adcd24c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 3, 224, 224), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd64d985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 3, 224, 224), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "443f197e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 18:10:15.050556: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "Some layers from the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing TFViTForImageClassification: ['vit/pooler/dense/kernel:0', 'vit/pooler/dense/bias:0']\n",
      "- This IS expected if you are initializing TFViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFViTForImageClassification, create_optimizer\n",
    "import tensorflow as tf\n",
    "# Replace \"your_fine_tuned_model_directory\" with the actual directory where your fine-tuned model is stored.\n",
    "# model2 = TFViTForImageClassification.from_pretrained(\"../vit-base-patch16-224-in21k\")\n",
    "# create optimizer wight weigh decay\n",
    "num_train_steps = len(tf_train_dataset) * num_train_epochs\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=weight_decay_rate,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    ")\n",
    "\n",
    "# # load pre-trained ViT model\n",
    "model = TFViTForImageClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(img_class_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "# define loss\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# define metrics\n",
    "metrics=[\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "    tf.keras.metrics.SparseTopKCategoricalAccuracy(3, name=\"top-3-accuracy\"),\n",
    "]\n",
    "\n",
    "# # compile model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=metrics\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "328924ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # alternatively create Image Classification model using Keras Layer and ViTModel\n",
    "# # here you can also add the processing layers of keras\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from transformers import TFViTModel\n",
    "\n",
    "# base_model = TFViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "\n",
    "# # inputs\n",
    "# pixel_values = tf.keras.layers.Input(shape=(3,224,224), name='pixel_values', dtype='float32')\n",
    "\n",
    "# # model layer\n",
    "# vit = base_model.vit(pixel_values)[0]\n",
    "# classifier = tf.keras.layers.Dense(10, activation='softmax', name='outputs')(vit[:, 0, :])\n",
    "\n",
    "# # model\n",
    "# keras_model = tf.keras.Model(inputs=pixel_values, outputs=classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea09c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "from tensorflow.keras.callbacks import TensorBoard as TensorboardCallback, EarlyStopping\n",
    "\n",
    "callbacks=[]\n",
    "\n",
    "callbacks.append(TensorboardCallback(log_dir=os.path.join(output_dir,\"logs\")))\n",
    "callbacks.append(EarlyStopping(monitor=\"val_accuracy\",patience=1))\n",
    "# if hub_token:\n",
    "#     callbacks.append(PushToHubCallback(output_dir=output_dir,\n",
    "#                                      hub_model_id=hub_model_id,\n",
    "#                                      hub_token=hub_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53e829bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "232/232 [==============================] - 110s 437ms/step - loss: 2.5037 - accuracy: 0.4941 - top-3-accuracy: 0.7306 - val_loss: 2.2297 - val_accuracy: 0.4703 - val_top-3-accuracy: 0.8218\n",
      "Epoch 2/20\n",
      "232/232 [==============================] - 101s 433ms/step - loss: 1.4556 - accuracy: 0.7525 - top-3-accuracy: 0.9491 - val_loss: 1.6644 - val_accuracy: 0.6683 - val_top-3-accuracy: 0.8927\n",
      "Epoch 3/20\n",
      "232/232 [==============================] - 102s 437ms/step - loss: 0.9242 - accuracy: 0.8695 - top-3-accuracy: 0.9801 - val_loss: 1.2632 - val_accuracy: 0.7178 - val_top-3-accuracy: 0.9092\n",
      "Epoch 4/20\n",
      "232/232 [==============================] - 101s 434ms/step - loss: 0.5892 - accuracy: 0.9288 - top-3-accuracy: 0.9926 - val_loss: 1.1234 - val_accuracy: 0.7475 - val_top-3-accuracy: 0.9076\n",
      "Epoch 5/20\n",
      "232/232 [==============================] - 103s 441ms/step - loss: 0.3857 - accuracy: 0.9646 - top-3-accuracy: 0.9966 - val_loss: 0.9960 - val_accuracy: 0.7607 - val_top-3-accuracy: 0.9092\n",
      "Epoch 6/20\n",
      "232/232 [==============================] - 101s 435ms/step - loss: 0.2590 - accuracy: 0.9823 - top-3-accuracy: 0.9973 - val_loss: 0.9338 - val_accuracy: 0.7525 - val_top-3-accuracy: 0.9092\n"
     ]
    }
   ],
   "source": [
    "train_results = model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_eval_dataset,\n",
    "    callbacks=callbacks,\n",
    "    epochs=num_train_epochs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7f9700f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f6614570610>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc01704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import HfApi\n",
    "\n",
    "# api = HfApi()\n",
    "\n",
    "# user = api.whoami(hub_token)\n",
    "\n",
    "\n",
    "feature_extractor.save_pretrained(output_dir)\n",
    "model.save_pretrained(output_dir)\n",
    "# api.upload_file(\n",
    "#     token=hub_token,\n",
    "#     repo_id=f\"{user['name']}/{hub_model_id}\",\n",
    "#     path_or_fileobj=os.path.join(output_dir,\"preprocessor_config.json\"),\n",
    "#     path_in_repo=\"preprocessor_config.json\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "813855c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suryansh/anaconda3/lib/python3.11/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "All model checkpoint layers were used when initializing TFViTForImageClassification.\n",
      "\n",
      "All the layers of TFViTForImageClassification were initialized from the model checkpoint at ./vit-base-patch16-224-in21k.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTForImageClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7504930966469427\n",
      "Classification Report:\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                     Apple Scab Leaf       0.64      0.50      0.56        14\n",
      "                          Apple leaf       0.80      0.75      0.77        16\n",
      "                     Apple rust leaf       0.68      0.93      0.79        14\n",
      "                    Bell_pepper leaf       0.79      0.71      0.75        48\n",
      "               Bell_pepper leaf spot       0.29      0.73      0.41        11\n",
      "                      Blueberry leaf       0.94      0.89      0.91       159\n",
      "                         Cherry leaf       0.65      0.73      0.69        15\n",
      "                 Corn Gray leaf spot       0.57      0.31      0.40        13\n",
      "                    Corn leaf blight       0.68      0.87      0.76        31\n",
      "                      Corn rust leaf       0.94      0.79      0.86        19\n",
      "                          Peach leaf       0.78      0.88      0.83        51\n",
      "                         Potato leaf       0.00      0.00      0.00         9\n",
      "            Potato leaf early blight       0.59      0.37      0.45        27\n",
      "             Potato leaf late blight       0.06      0.33      0.11         3\n",
      "                      Raspberry leaf       0.95      0.92      0.93        76\n",
      "                       Soyabean leaf       0.52      0.78      0.62        18\n",
      "          Squash Powdery mildew leaf       0.83      1.00      0.91        20\n",
      "                     Strawberry leaf       0.96      0.96      0.96        67\n",
      "            Tomato Early blight leaf       0.33      0.40      0.36        10\n",
      "           Tomato Septoria leaf spot       0.76      0.53      0.62        66\n",
      "                         Tomato leaf       0.78      0.90      0.84        51\n",
      "          Tomato leaf bacterial spot       0.17      0.20      0.18        35\n",
      "             Tomato leaf late blight       0.71      0.56      0.63        18\n",
      "            Tomato leaf mosaic virus       0.41      0.23      0.30        30\n",
      "            Tomato leaf yellow virus       0.78      0.92      0.84       109\n",
      "                    Tomato mold leaf       0.72      0.55      0.63        47\n",
      "Tomato two spotted spider mites leaf       0.00      0.00      0.00         2\n",
      "                          grape leaf       0.92      0.88      0.90        25\n",
      "                grape leaf black rot       1.00      0.80      0.89        10\n",
      "\n",
      "                            accuracy                           0.75      1014\n",
      "                           macro avg       0.63      0.63      0.62      1014\n",
      "                        weighted avg       0.76      0.75      0.75      1014\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suryansh/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/suryansh/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/suryansh/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTFeatureExtractor, TFViTForImageClassification\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Load the feature extractor and the trained ViT model\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('./vit-base-patch16-224-in21k')\n",
    "model = TFViTForImageClassification.from_pretrained('./vit-base-patch16-224-in21k')\n",
    "\n",
    "# Path to the test directory\n",
    "test_dir = './cropped_images_dataset/test'\n",
    "\n",
    "# List all subdirectories (each subdirectory corresponds to a class)\n",
    "class_names = os.listdir(test_dir)\n",
    "\n",
    "# Lists to store true labels and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Iterate through each class directory\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(test_dir, class_name)\n",
    "\n",
    "    # Iterate through images in the class directory\n",
    "    for image_name in os.listdir(class_path):\n",
    "        image_path = os.path.join(class_path, image_name)\n",
    "\n",
    "        # Open and preprocess the image\n",
    "        image = Image.open(image_path)\n",
    "        inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "        pixel_values_tensor = tf.convert_to_tensor(inputs['pixel_values'], dtype=tf.float32)\n",
    "        # Make predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model(pixel_values=pixel_values_tensor)\n",
    "            logits = outputs.logits\n",
    "            logits = tf.nn.softmax(logits)\n",
    "            # model predicts one of the 1000 ImageNet classes\n",
    "            predicted_class_idx = tf.argmax(logits, axis=-1).numpy().item()\n",
    "            \n",
    "        # Append true and predicted labels\n",
    "        true_labels.append(class_name)\n",
    "        predicted_labels.append(model.config.id2label[predicted_class_idx])\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report:\\n{report}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8abdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
