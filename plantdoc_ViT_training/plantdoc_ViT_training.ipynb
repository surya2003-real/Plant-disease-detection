{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5476aaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/suryansh/.local/lib/python3.10/site-packages (4.36.0)\n",
      "Requirement already satisfied: datasets>=1.17.0 in /home/suryansh/.local/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorboard in /home/suryansh/.local/lib/python3.10/site-packages (2.15.1)\n",
      "Requirement already satisfied: filelock in /home/suryansh/.local/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/suryansh/.local/lib/python3.10/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/suryansh/.local/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/suryansh/.local/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/suryansh/.local/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/suryansh/.local/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/suryansh/.local/lib/python3.10/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/suryansh/.local/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/suryansh/.local/lib/python3.10/site-packages (from datasets>=1.17.0) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/suryansh/.local/lib/python3.10/site-packages (from datasets>=1.17.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/suryansh/.local/lib/python3.10/site-packages (from datasets>=1.17.0) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/suryansh/.local/lib/python3.10/site-packages (from datasets>=1.17.0) (2.1.3)\n",
      "Requirement already satisfied: xxhash in /home/suryansh/.local/lib/python3.10/site-packages (from datasets>=1.17.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/suryansh/.local/lib/python3.10/site-packages (from datasets>=1.17.0) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/suryansh/.local/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets>=1.17.0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/suryansh/.local/lib/python3.10/site-packages (from datasets>=1.17.0) (3.9.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/suryansh/.local/lib/python3.10/site-packages (from tensorboard) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/suryansh/.local/lib/python3.10/site-packages (from tensorboard) (1.59.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/suryansh/.local/lib/python3.10/site-packages (from tensorboard) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/suryansh/.local/lib/python3.10/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/suryansh/.local/lib/python3.10/site-packages (from tensorboard) (3.5.1)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /home/suryansh/.local/lib/python3.10/site-packages (from tensorboard) (4.23.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard) (59.6.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/suryansh/.local/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/suryansh/.local/lib/python3.10/site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/suryansh/.local/lib/python3.10/site-packages (from aiohttp->datasets>=1.17.0) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/suryansh/.local/lib/python3.10/site-packages (from aiohttp->datasets>=1.17.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/suryansh/.local/lib/python3.10/site-packages (from aiohttp->datasets>=1.17.0) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/suryansh/.local/lib/python3.10/site-packages (from aiohttp->datasets>=1.17.0) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/suryansh/.local/lib/python3.10/site-packages (from aiohttp->datasets>=1.17.0) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/suryansh/.local/lib/python3.10/site-packages (from aiohttp->datasets>=1.17.0) (4.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/suryansh/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/suryansh/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/suryansh/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/suryansh/.local/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/suryansh/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/suryansh/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/suryansh/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/suryansh/.local/lib/python3.10/site-packages (from pandas->datasets>=1.17.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets>=1.17.0) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/suryansh/.local/lib/python3.10/site-packages (from pandas->datasets>=1.17.0) (2023.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/suryansh/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install \"tensorflow==2.6.0\"\n",
    "!pip install transformers \"datasets>=1.17.0\" tensorboard --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "647ca002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae4b2850f824923871b3153ee36a78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06cd583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/vit-base-patch16-224-in21k\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07624179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datasets\n",
    "\n",
    "def create_image_folder_dataset(root_path):\n",
    "    \"\"\"creates `Dataset` from image folder structure\"\"\"\n",
    "\n",
    "    # get class names by folders names\n",
    "    _CLASS_NAMES= os.listdir(root_path)\n",
    "    # defines `datasets` features`\n",
    "    features=datasets.Features({\n",
    "                      \"img\": datasets.Image(),\n",
    "                      \"label\": datasets.features.ClassLabel(names=_CLASS_NAMES),\n",
    "                  })\n",
    "    # temp list holding datapoints for creation\n",
    "    img_data_files=[]\n",
    "    label_data_files=[]\n",
    "    # load images into list for creation\n",
    "    for img_class in os.listdir(root_path):\n",
    "        for img in os.listdir(os.path.join(root_path,img_class)):\n",
    "            path_=os.path.join(root_path,img_class,img)\n",
    "            img_data_files.append(path_)\n",
    "            label_data_files.append(img_class)\n",
    "    # create dataset\n",
    "    ds = datasets.Dataset.from_dict({\"img\":img_data_files,\"label\":label_data_files},features=features)\n",
    "    return ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "524e8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "eurosat_ds = create_image_folder_dataset(\"./CROP/CROP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52685247",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_class_labels = eurosat_ds.features[\"label\"].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5859cd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 23:08:46.313033: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-13 23:08:46.564822: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-13 23:08:46.564903: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-13 23:08:46.580647: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-13 23:08:46.664110: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-13 23:08:47.380834: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/suryansh/anaconda3/lib/python3.11/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "2023-12-13 23:08:48.734458: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 23:08:48.739616: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 23:08:48.739701: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 23:08:48.741776: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 23:08:48.741845: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 23:08:48.741989: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 23:08:48.838315: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 23:08:48.838421: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 23:08:48.838490: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 23:08:48.838553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6263 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTFeatureExtractor\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_id)\n",
    "\n",
    "# learn more about data augmentation here: https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Resizing(feature_extractor.size['height'], feature_extractor.size['width']),\n",
    "        layers.Rescaling(1./255),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# use keras image data augementation processing\n",
    "def augmentation(examples):\n",
    "    # print(examples[\"img\"])\n",
    "    examples[\"pixel_values\"] = [data_augmentation(image) for image in examples[\"img\"]]\n",
    "    return examples\n",
    "\n",
    "\n",
    "# basic processing (only resizing)\n",
    "def process(examples):\n",
    "    examples.update(feature_extractor(examples['img'], ))\n",
    "    return examples\n",
    "\n",
    "# we are also renaming our label col to labels to use `.to_tf_dataset` later\n",
    "eurosat_ds = eurosat_ds.rename_column(\"label\", \"labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20c7612d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2363 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['img', 'labels', 'pixel_values'],\n",
       "    num_rows: 2363\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processed_dataset = eurosat_ds.map(process, batched=True)\n",
    "\n",
    "# # augmenting dataset takes a lot of time\n",
    "processed_dataset = eurosat_ds.map(augmentation, batched=True)\n",
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df3e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test size will be 15% of train dataset\n",
    "test_size=.15\n",
    "\n",
    "processed_dataset = processed_dataset.shuffle().train_test_split(test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "497be668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 Laptop GPU, compute capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 23:13:29.183252: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "import tensorflow as tf\n",
    "\n",
    "id2label = {str(i): label for i, label in enumerate(img_class_labels)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "num_train_epochs = 10\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 32\n",
    "learning_rate = 3e-5\n",
    "weight_decay_rate=0.01\n",
    "num_warmup_steps=0\n",
    "output_dir=model_id.split(\"/\")[1]\n",
    "# hub_token = HfFolder.get_token() # or your token directly \"hf_xxx\"\n",
    "# hub_model_id = f'{model_id.split(\"/\")[1]}-euroSat'\n",
    "fp16=True\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "# Comment this line out if you're using a GPU that will not benefit from this\n",
    "if fp16:\n",
    "    tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1835ea54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2008 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suryansh/anaconda3/lib/python3.11/site-packages/datasets/arrow_dataset.py:388: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "# Data collator that will dynamically pad the inputs received, as well as the labels.\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "# Function to process a single example\n",
    "def process_example(example):\n",
    "    # Transpose the pixel_values tensor to have channels dimension at the beginning\n",
    "    example['pixel_values'] = tf.transpose(example['pixel_values'], perm=[0, 3, 2, 1])\n",
    "    return example\n",
    "\n",
    "# Modify the processed_dataset directly\n",
    "processed_dataset['train'] = processed_dataset['train'].map(\n",
    "    process_example,\n",
    "    batched=True,\n",
    "    num_proc=1  # Set the number of processes according to your system capabilities\n",
    ")\n",
    "# Modify the processed_dataset directly\n",
    "processed_dataset['test'] = processed_dataset['test'].map(\n",
    "    process_example,\n",
    "    batched=True,\n",
    "    num_proc=1  # Set the number of processes according to your system capabilities\n",
    ")\n",
    "# converting our train dataset to tf.data.Dataset\n",
    "tf_train_dataset = processed_dataset[\"train\"].to_tf_dataset(\n",
    "   columns=['pixel_values'],\n",
    "   label_cols=[\"labels\"],\n",
    "   shuffle=True,\n",
    "   batch_size=train_batch_size,\n",
    "   collate_fn=data_collator)\n",
    "\n",
    "# converting our test dataset to tf.data.Dataset\n",
    "tf_eval_dataset = processed_dataset[\"test\"].to_tf_dataset(\n",
    "   columns=['pixel_values'],\n",
    "   label_cols=[\"labels\"],\n",
    "   shuffle=True,\n",
    "   batch_size=eval_batch_size,\n",
    "   collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adcd24c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 3, 224, 224), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "443f197e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 23:18:29.881041: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "All model checkpoint layers were used when initializing TFViTForImageClassification.\n",
      "\n",
      "All the layers of TFViTForImageClassification were initialized from the model checkpoint at ../vit-base-patch16-224-in21k.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTForImageClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFViTForImageClassification, create_optimizer\n",
    "import tensorflow as tf\n",
    "# Replace \"your_fine_tuned_model_directory\" with the actual directory where your fine-tuned model is stored.\n",
    "model2 = TFViTForImageClassification.from_pretrained(\"../vit-base-patch16-224-in21k\")\n",
    "# create optimizer wight weigh decay\n",
    "num_train_steps = len(tf_train_dataset) * num_train_epochs\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=weight_decay_rate,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    ")\n",
    "\n",
    "# # load pre-trained ViT model\n",
    "# model = TFViTForImageClassification.from_pretrained(\n",
    "#     model_id,\n",
    "#     num_labels=len(img_class_labels),\n",
    "#     id2label=id2label,\n",
    "#     label2id=label2id,\n",
    "# )\n",
    "\n",
    "# define loss\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# define metrics\n",
    "metrics=[\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "    tf.keras.metrics.SparseTopKCategoricalAccuracy(3, name=\"top-3-accuracy\"),\n",
    "]\n",
    "\n",
    "# # compile model\n",
    "model2.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=metrics\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328924ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # alternatively create Image Classification model using Keras Layer and ViTModel\n",
    "# # here you can also add the processing layers of keras\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from transformers import TFViTModel\n",
    "\n",
    "# base_model = TFViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "\n",
    "# # inputs\n",
    "# pixel_values = tf.keras.layers.Input(shape=(3,224,224), name='pixel_values', dtype='float32')\n",
    "\n",
    "# # model layer\n",
    "# vit = base_model.vit(pixel_values)[0]\n",
    "# classifier = tf.keras.layers.Dense(10, activation='softmax', name='outputs')(vit[:, 0, :])\n",
    "\n",
    "# # model\n",
    "# keras_model = tf.keras.Model(inputs=pixel_values, outputs=classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea09c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "from tensorflow.keras.callbacks import TensorBoard as TensorboardCallback, EarlyStopping\n",
    "\n",
    "callbacks=[]\n",
    "\n",
    "callbacks.append(TensorboardCallback(log_dir=os.path.join(output_dir,\"logs\")))\n",
    "callbacks.append(EarlyStopping(monitor=\"val_accuracy\",patience=2))\n",
    "# if hub_token:\n",
    "#     callbacks.append(PushToHubCallback(output_dir=output_dir,\n",
    "#                                      hub_model_id=hub_model_id,\n",
    "#                                      hub_token=hub_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53e829bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 45s 572ms/step - loss: 1.0624 - accuracy: 0.7480 - top-3-accuracy: 0.9412 - val_loss: 0.8909 - val_accuracy: 0.8085 - val_top-3-accuracy: 0.9493\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 34s 544ms/step - loss: 0.6722 - accuracy: 0.8855 - top-3-accuracy: 0.9791 - val_loss: 0.8533 - val_accuracy: 0.8056 - val_top-3-accuracy: 0.9606\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 36s 563ms/step - loss: 0.4772 - accuracy: 0.9492 - top-3-accuracy: 0.9885 - val_loss: 0.8240 - val_accuracy: 0.8028 - val_top-3-accuracy: 0.9606\n"
     ]
    }
   ],
   "source": [
    "train_results = model2.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_eval_dataset,\n",
    "    callbacks=callbacks,\n",
    "    epochs=num_train_epochs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7f9700f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f96a8156d50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc01704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import HfApi\n",
    "\n",
    "# api = HfApi()\n",
    "\n",
    "# user = api.whoami(hub_token)\n",
    "\n",
    "\n",
    "feature_extractor.save_pretrained(output_dir)\n",
    "model2.save_pretrained(output_dir)\n",
    "# api.upload_file(\n",
    "#     token=hub_token,\n",
    "#     repo_id=f\"{user['name']}/{hub_model_id}\",\n",
    "#     path_or_fileobj=os.path.join(output_dir,\"preprocessor_config.json\"),\n",
    "#     path_in_repo=\"preprocessor_config.json\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea87ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
